{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "sys.path.append(module_path)\n",
    "\n",
    "from Weighted_VP_model import *\n",
    "sys.path.append(os.path.abspath('../Weighted_VP_model'))\n",
    "\n",
    "from vpnet import *\n",
    "from vpnet.vp_functions import *\n",
    "from spike_classification import *\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\darab\\Documents\\PROJECTS\\VP_microneurography\\code\\data_handling.py:56: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  all_spike['track'] = all_spike['track'].replace(replacement_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val timestamps shape (403573, 15)\n",
      "val_samples shape torch.Size([403573, 1, 15])\n",
      "class1 count 25000\n",
      "class0 count 75000\n",
      "Balanced shapes:  torch.Size([100000, 1, 15]) torch.Size([100000, 2]) torch.Size([100000, 4])\n",
      "class1 count 25000\n",
      "class0 count 75000\n",
      "Balanced shapes:  torch.Size([100000, 1, 15]) torch.Size([100000, 2]) torch.Size([100000, 4])\n",
      "Dataloaders are ready\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data_handling import *\n",
    "\n",
    "dtype = torch.float64\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "window_size_ = 15\n",
    "overlapping_size_ = 11\n",
    "\n",
    "dataSet = NeurographyDataset()\n",
    "path = f'window_{window_size_}_overlap_{overlapping_size_}_corrected.pkl'\n",
    "full_path = os.path.join('../data', path)\n",
    "dataSet.load_samples_and_labels_from_file(path)\n",
    "\n",
    "dataloaders = dataSet.random_split_undersampling()\n",
    "\n",
    "n_channels, n_in = dataSet.samples[0].shape\n",
    "n_out = len(dataSet.binary_labels_onehot[0])\n",
    "hidden1 = 3\n",
    "weight_num = 2\n",
    "affin = torch.tensor([6 / n_in, -0.3606]).tolist()\n",
    "#affin = torch.tensor([6 / n_in, -0.3606]).tolist()  #semioptimal\n",
    "weight = ((torch.rand(weight_num)-0.5)*8).tolist()\n",
    "\n",
    "model = VPNet(n_in, n_channels, hidden1, VPTypes.FEATURES, affin + weight, WeightedHermiteSystem(n_in, hidden1, weight_num), [hidden1], n_out, device=device, dtype=dtype)\n",
    "model.load_state_dict(torch.load('trained_models/widnow_15_overlapping_11_hidden_3_nweight_2_id_1', weights_only=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Label 0:\n",
      "  True Positives (TP): 0.0\n",
      "  False Negatives (FN): 0.0\n",
      "  False Positives (FP): 37789.0\n",
      "  True Negatives (TN): 365013.0\n",
      "\n",
      "Label 1:\n",
      "  True Positives (TP): 252.0\n",
      "  False Negatives (FN): 11.0\n",
      "  False Positives (FP): 0.0\n",
      "  True Negatives (TN): 0.0\n",
      "\n",
      "Label 2:\n",
      "  True Positives (TP): 250.0\n",
      "  False Negatives (FN): 5.0\n",
      "  False Positives (FP): 0.0\n",
      "  True Negatives (TN): 0.0\n",
      "\n",
      "Label 3:\n",
      "  True Positives (TP): 240.0\n",
      "  False Negatives (FN): 13.0\n",
      "  False Positives (FP): 0.0\n",
      "  True Negatives (TN): 0.0\n",
      "\n",
      "========================================\n",
      "Shape of all_multiple_labels: (403573,)\n",
      "========================================\n",
      "Val accuracy: 90.63%, loss: 16.8474\n",
      "================================================================================\n",
      "========================================\n",
      "           MODEL METRICS          \n",
      "========================================\n",
      "Precision : 0.0193\n",
      "Recall    : 0.9624\n",
      "F1-Score  : 0.0378\n",
      "========================================\n",
      "       CONFUSION MATRIX           \n",
      "========================================\n",
      "              Predicted\n",
      "          365013    37789\n",
      "Actual    29    742\n",
      "========================================\n",
      "ROC-AUC   : 0.9343\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "decision_boundary = 0.5\n",
    "class_weights = torch.tensor([0.003, 0.997]).to(device)\n",
    "weighted_criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "criterion = VPLoss(weighted_criterion, 0.1)\n",
    "val_accuracy, val_loss, test_labels, test_predictions, test_probabilities = test(model, dataloaders['val_loader'], criterion, decision_boundary)\n",
    "compute_metrics(test_labels, test_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_samples = []\n",
    "for data in dataloaders['val_loader']:\n",
    "    x, labels, multiple = data\n",
    "    all_samples.append(x.cpu())\n",
    "all_samples = torch.cat(all_samples).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([403573, 15])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6053595,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloaders['val_timestamps'].flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([403573]) torch.Size([403573]) torch.Size([403573, 2]) torch.Size([403573, 15])\n"
     ]
    }
   ],
   "source": [
    "print(test_labels.shape, test_predictions.shape, test_probabilities.shape, all_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.lines import Line2D\n",
    "# Flatten the samples back into continuous data\n",
    "flattened_samples = all_samples.flatten()\n",
    "\n",
    "# Define the number of windows to plot at a time\n",
    "windows_to_plot = 5\n",
    "window_size = all_samples.shape[1]  # Number of points in each window\n",
    "\n",
    "# Extract probabilities from the second column (corresponding to the class of interest)\n",
    "probabilities = test_probabilities[:, 1]\n",
    "\n",
    "# Define the color mapping based on the percentage categories (10 colors)\n",
    "cmap = plt.get_cmap('tab10')  # 10 distinct colors\n",
    "color_bins = np.digitize(probabilities * 100, bins=np.arange(0, 101, 10)) - 1  # 0-9%, 10-19%, ..., 90-100%\n",
    "\n",
    "# Total number of windows\n",
    "total_windows = all_samples.shape[0]\n",
    "\n",
    "# Create a list of colors and percentage labels for the legend\n",
    "percentage_labels = [f'{i*10}-{(i+1)*10-1}%' for i in range(10)]\n",
    "legend_elements = [Line2D([0], [0], marker='o', color='w', label=label, \n",
    "                          markerfacecolor=cmap(i), markersize=10) for i, label in enumerate(percentage_labels)]\n",
    "\n",
    "# Loop to plot windows in chunks of 5\n",
    "for i in range(0, windows_to_plot, windows_to_plot):\n",
    "    # Get the subset of windows to plot\n",
    "    start = i * window_size\n",
    "    end = min((i + windows_to_plot) * window_size, flattened_samples.shape[0])\n",
    "    \n",
    "    # Get the probabilities and corresponding color bin for the current windows\n",
    "    window_probabilities = probabilities[i:i + windows_to_plot]\n",
    "    window_colors = color_bins[i:i + windows_to_plot]\n",
    "    \n",
    "    # Create scatter plot for this range of windows\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    # For each window, scatter plot the points and assign color based on its probability category\n",
    "    for j in range(windows_to_plot):\n",
    "        window_start = start + j * window_size\n",
    "        window_end = window_start + window_size\n",
    "        \n",
    "        plt.scatter(range(window_start, window_end),\n",
    "                    flattened_samples[window_start:window_end],\n",
    "                    c=[cmap(window_colors[j])] * window_size,  # Same color for all points in a window\n",
    "                    alpha=0.6, s=10)\n",
    "    \n",
    "    # Add legend for probability categories\n",
    "    plt.legend(handles=legend_elements, title=\"Probability (%)\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.title(f\"Scatter Plot of Windows {i} to {i + windows_to_plot - 1}\")\n",
    "    plt.xlabel('Sample index')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataSet.all_differentiated_spikes\n",
    "# Flatten the samples back into continuous data\n",
    "flattened_samples = all_samples.flatten()\n",
    "\n",
    "# Define the number of windows to plot at a time\n",
    "windows_to_plot = 15\n",
    "window_size = all_samples.shape[1]  # Number of points in each window\n",
    "\n",
    "# Extract probabilities from the second column (corresponding to the class of interest)\n",
    "probabilities = test_probabilities[:, 1]\n",
    "\n",
    "# Define the color mapping based on the percentage categories (10 colors)\n",
    "cmap = plt.get_cmap('tab10')  # 10 distinct colors\n",
    "color_bins = np.digitize(probabilities * 100, bins=np.arange(0, 101, 10)) - 1  # 0-9%, 10-19%, ..., 90-100%\n",
    "\n",
    "# Define track colors\n",
    "track_colors = {0: 'red', 1: 'green', 2: 'blue', 3: 'purple'}\n",
    "\n",
    "# Create a list of colors and percentage labels for the legend\n",
    "percentage_labels = [f'{i*10}-{(i+1)*10-1}%' for i in range(10)]\n",
    "legend_elements = [Line2D([0], [0], marker='o', color='w', label=label, \n",
    "                          markerfacecolor=cmap(i), markersize=10) for i, label in enumerate(percentage_labels)]\n",
    "\n",
    "# Add track legend elements\n",
    "track_legend_elements = [Line2D([0], [0], color=track_colors[i], lw=2, label=f'Track {i}') for i in track_colors]\n",
    "\n",
    "# Loop to plot windows in chunks of 5\n",
    "for i in range(0, windows_to_plot*10, windows_to_plot):\n",
    "    # Get the subset of windows to plot\n",
    "    start = i * window_size\n",
    "    end = min((i + windows_to_plot) * window_size, flattened_samples.shape[0])\n",
    "    \n",
    "    # Get the probabilities and corresponding color bin for the current windows\n",
    "    window_probabilities = probabilities[i:i + windows_to_plot]\n",
    "    window_colors = color_bins[i:i + windows_to_plot]\n",
    "    \n",
    "    # Create scatter plot for this range of windows\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    \n",
    "    # For each window, scatter plot the points and assign color based on its probability category\n",
    "    for j in range(windows_to_plot):\n",
    "        window_start = start + j * window_size\n",
    "        window_end = window_start + window_size\n",
    "        \n",
    "        plt.scatter(range(window_start, window_end),\n",
    "                    flattened_samples[window_start:window_end],\n",
    "                    c=[cmap(window_colors[j])] * window_size,  # Same color for all points in a window\n",
    "                    alpha=0.6, s=10)\n",
    "    \n",
    "    # Plot vertical lines based on dataframe timestamps and track values\n",
    "    window_timestamps = dataloaders['val_timestamps'][i:i + windows_to_plot]  # Select the relevant window timestamps\n",
    "    for _, row in df.iterrows():\n",
    "        # Check if the timestamp from the dataframe is within the current windows\n",
    "        for j in range(windows_to_plot):\n",
    "            if row['ts'] >= window_timestamps[j].min() and row['ts'] <= window_timestamps[j].max():\n",
    "                # Find the index of the timestamp in the window\n",
    "                timestamp_index_within_window = np.argmin(np.abs(window_timestamps[j] - row['ts']))\n",
    "                global_index = start + j * window_size + timestamp_index_within_window\n",
    "                # Plot the vertical line with the color corresponding to the track value\n",
    "                plt.axvline(x=global_index, color=track_colors[row['track']], linestyle='--', lw=2)\n",
    "    \n",
    "    # Add legends\n",
    "    plt.legend(handles=legend_elements + track_legend_elements, title=\"Probability (%) and Track\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.title(f\"Scatter Plot of Windows {i} to {i + windows_to_plot - 1}\")\n",
    "    plt.xlabel('Sample index')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.tight_layout()\n",
    "    plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5947\n",
      "5948\n",
      "5949\n",
      "5950\n",
      "5971\n",
      "5972\n",
      "5973\n",
      "5974\n",
      "15947\n",
      "15948\n"
     ]
    }
   ],
   "source": [
    "df = dataSet.all_differentiated_spikes\n",
    "first_matching_window_index = None  # Initialize variable to hold the index of the first matching window\n",
    "counter = 0\n",
    "for i in range(len(dataloaders['val_timestamps'])):  # Loop through all windows\n",
    "    window_timestamps = dataloaders['val_timestamps'][i]  # Get the current window's timestamps\n",
    "    # Check for matches between the window's timestamps and the DataFrame\n",
    "    if any(np.isin(window_timestamps, df['ts'].values)):  # Check for any matches\n",
    "        first_matching_window_index = i  # Set the index of the first matching window\n",
    "        print(i)\n",
    "        counter += 1\n",
    "        if counter == 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6053595])\n"
     ]
    }
   ],
   "source": [
    "#overlapping not handled\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "df = dataSet.all_differentiated_spikes\n",
    "flattened_samples = all_samples.flatten()\n",
    "print(flattened_samples.shape)\n",
    "\n",
    "# Define the number of windows to plot at a time\n",
    "windows_to_plot = 100\n",
    "window_size = all_samples.shape[1]  # Number of points in each window\n",
    "\n",
    "# Extract probabilities from the second column (corresponding to the class of interest)\n",
    "probabilities = test_probabilities[:, 1]\n",
    "\n",
    "# Define the color mapping based on 4 distinct categories\n",
    "cmap = plt.get_cmap('tab10', 4)  # Using a colormap that supports 4 colors\n",
    "color_bins = np.digitize(probabilities * 100, bins=np.linspace(0, 100, 5)) - 1  # 0-24%, 25-49%, 50-74%, 75-100%\n",
    "\n",
    "# Define track colors\n",
    "track_colors = {0: 'red', 1: 'green', 2: 'blue', 3: 'purple'}  # Ensure to include all track values\n",
    "\n",
    "# Create a list of colors and percentage labels for the legend\n",
    "percentage_labels = [f'{i * 25}-{(i + 1) * 25 - 1}%' for i in range(4)]  # Update for 4 categories\n",
    "legend_elements = [Line2D([0], [0], marker='o', color='w', label=label, \n",
    "                          markerfacecolor=cmap(i), markersize=10) for i, label in enumerate(percentage_labels)]\n",
    "\n",
    "# Add track legend elements\n",
    "track_legend_elements = [Line2D([0], [0], color=track_colors[i], lw=2, label=f'Track {i}') for i in track_colors]\n",
    "\n",
    "# Define the index of the first matching timestamp window\n",
    "first_matching_index = 5947\n",
    "first_matching_index = 15947\n",
    "\n",
    "# Calculate the start index for plotting windows around the first matching index\n",
    "start_index = max(0, first_matching_index - windows_to_plot // 2)  # Start plotting a few windows before the matching index\n",
    "end_index = start_index + windows_to_plot  # Number of windows to plot\n",
    "\n",
    "# Create a scatter plot for the windows around the first matching timestamp\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "# Loop to plot windows in the defined range\n",
    "for i in range(start_index, end_index):\n",
    "    # Get the subset of windows to plot\n",
    "    start = i * window_size\n",
    "    window_end = start + window_size\n",
    "\n",
    "    # Get the probabilities and corresponding color bin for the current window\n",
    "    window_probabilities = probabilities[i]\n",
    "    window_colors = color_bins[i]\n",
    "    \n",
    "    # Scatter plot for this window\n",
    "    plt.scatter(range(start, window_end),\n",
    "                flattened_samples[start:window_end],\n",
    "                c=[cmap(window_colors)] * window_size,  # Same color for all points in a window\n",
    "                alpha=0.6, s=10)\n",
    "\n",
    "    # Plot vertical lines based on dataframe timestamps and track values\n",
    "    window_timestamps = dataloaders['val_timestamps'][i:i + 1]  # Select the relevant window timestamps\n",
    "    for _, row in df.iterrows():\n",
    "        # Check if the timestamp from the dataframe is within the current window\n",
    "        if row['ts'] >= window_timestamps.min() and row['ts'] <= window_timestamps.max():\n",
    "            # Find the index of the timestamp in the window\n",
    "            timestamp_index_within_window = np.argmin(np.abs(window_timestamps - row['ts']))\n",
    "            global_index = start + timestamp_index_within_window\n",
    "            # Plot the vertical line with the color corresponding to the track value\n",
    "            plt.axvline(x=global_index, color=track_colors[int(row['track'])], linestyle='--', lw=2)  # Convert to int\n",
    "\n",
    "# Add legends\n",
    "plt.legend(handles=legend_elements + track_legend_elements, title=\"Probability (%) and Track\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.title(f\"Scatter Plot of Windows Around Index {first_matching_index}\")\n",
    "plt.xlabel('Sample index')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.tight_layout()\n",
    "plt.show(block=True)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1614303,), (1614303,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reconstruct_original_sequence(overlapping_windows, window_size, overlapping):\n",
    "    # Ensure the input is a NumPy array\n",
    "    overlapping_windows = np.asarray(overlapping_windows)\n",
    "\n",
    "    # Calculate the original length\n",
    "    num_windows = len(overlapping_windows)\n",
    "    stride = window_size - overlapping\n",
    "    original_length = (num_windows - 1) * stride + window_size\n",
    "    \n",
    "    # Initialize an array to store the reconstructed sequence\n",
    "    reconstructed_sequence = np.zeros(original_length)\n",
    "    \n",
    "    # Create an array to track how many times each index has been populated\n",
    "    count_array = np.zeros(original_length)\n",
    "\n",
    "    # Loop through the windows to reconstruct the sequence\n",
    "    for i in range(num_windows):\n",
    "        start_index = i * stride\n",
    "        end_index = start_index + window_size\n",
    "        \n",
    "        # Add the window values to the appropriate positions in the reconstructed sequence\n",
    "        reconstructed_sequence[start_index:end_index] += overlapping_windows[i]\n",
    "        \n",
    "        # Increment the count for the positions populated by this window\n",
    "        count_array[start_index:end_index] += 1\n",
    "\n",
    "    # Divide by the count to fill in the overlapping parts correctly\n",
    "    non_zero_count_mask = count_array > 0\n",
    "    reconstructed_sequence[non_zero_count_mask] /= count_array[non_zero_count_mask]\n",
    "    \n",
    "    # Fill NaN values if any (can happen at the beginning or end)\n",
    "    reconstructed_sequence = np.nan_to_num(reconstructed_sequence)\n",
    "\n",
    "    return reconstructed_sequence\n",
    "original_val_samples = reconstruct_original_sequence(all_samples, 15, 11)\n",
    "original_val_ts = reconstruct_original_sequence(dataloaders['val_timestamps'], 15, 11)\n",
    "original_val_samples.shape, original_val_ts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_ts = original_val_ts[0]\n",
    "end_ts = original_val_ts[-1]\n",
    "\n",
    "# Find the first row index in df where 'ts' is greater than or equal to start_ts\n",
    "start_index = df['ts'].searchsorted(start_ts, side='left')\n",
    "\n",
    "# Find the last row index in df where 'ts' is less than or equal to end_ts\n",
    "end_index = df['ts'].searchsorted(end_ts, side='right')\n",
    "\n",
    "# Slice df to only include rows within the range of original_val_ts timestamps\n",
    "df_val_range = df.iloc[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80609"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_ts_df_val_range = df_val_range['ts'].iloc[0]\n",
    "\n",
    "# Convert dataloaders['val_timestamps'] to a NumPy array if it isn't one already\n",
    "val_timestamps_array = np.array(dataloaders['val_timestamps'])\n",
    "\n",
    "closest_index = np.argmin(np.abs(val_timestamps_array - first_ts_df_val_range))\n",
    "\n",
    "# Retrieve the closest timestamp value for reference\n",
    "closest_ts = val_timestamps_array[closest_index]\n",
    "closest_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting range: 2487.817794082538 2488.117694082538\n",
      "First spike timestamp in df_val_range: 2487.838394082541\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "# Assuming dataloaders and original_val_ts are already defined\n",
    "df = dataSet.all_differentiated_spikes\n",
    "ts_windows_array = np.array(dataloaders['val_timestamps'])\n",
    "total_windows = len(original_val_ts)\n",
    "probabilities = test_probabilities[:, 1]\n",
    "\n",
    "\n",
    "# Initialize a list to store the highest probabilities\n",
    "# Define the index of the first matching timestamp window\n",
    "sample_size = 3000  # Number of windows to plot at a time\n",
    "custom_colors = ['#00008B', '#ADD8E6', '#FFFF00', '#FFA500', '#FF0000']  # Adjust colors as needed\n",
    "\n",
    "# Adjust bins for custom ranges\n",
    "bins = [0, 25, 50, 70, 90, 100]  # Custom bin edges\n",
    "\n",
    "# Set up labels for the new ranges\n",
    "percentage_labels = ['0-25%', '25-50%', '50-70%', '70-90%', '90-100%']\n",
    "legend_elements = [Line2D([0], [0], marker='o', color='w', label=label,\n",
    "                          markerfacecolor=custom_colors[i], markersize=10) for i, label in enumerate(percentage_labels)]\n",
    "track_colors = { 1: 'black', 2: 'yellow', 3: 'green'}\n",
    "\n",
    "for start_index in range(21300, 21300+sample_size*1, sample_size):\n",
    "    highest_probabilities = []\n",
    "    end_index = start_index + sample_size\n",
    "    # Get relevant timestamps and their corresponding probabilities\n",
    "    for ts in original_val_ts[start_index:end_index]:\n",
    "        # Create a boolean mask for the current timestamp\n",
    "        window_mask = np.any((ts_windows_array == ts), axis=1)\n",
    "        window_indices = np.where(window_mask)[0]\n",
    "\n",
    "        if window_indices.size > 0:\n",
    "            probs = probabilities[window_indices].numpy()\n",
    "            highest_probability = np.mean(probs)\n",
    "        else:\n",
    "            highest_probability = np.nan\n",
    "\n",
    "        highest_probabilities.append(highest_probability)\n",
    "\n",
    "    # Create a DataFrame to store the results\n",
    "    df_orig = pd.DataFrame({\n",
    "        'Timestamp': original_val_ts[start_index:end_index],\n",
    "        'Samples': original_val_samples[start_index:end_index],\n",
    "        'Probability': highest_probabilities\n",
    "    })\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(20, 6))\n",
    "\n",
    "    # Define color bins based on probabilities\n",
    "    color_bins = np.digitize(df_orig['Probability'] * 100, bins=bins) - 1\n",
    "\n",
    "    track_legend_elements = [Line2D([0], [0], color=track_colors[i], lw=2, label=f'Track {i}') for i in track_colors]\n",
    "\n",
    "    # Scatter plot for this window\n",
    "    plt.scatter(df_orig['Timestamp'],\n",
    "                df_orig['Samples'],\n",
    "                c=[custom_colors[color_bins[i]] for i in range(len(color_bins))],  # Color according to bins\n",
    "                alpha=0.6, s=10)\n",
    "\n",
    "    # Add vertical lines based on DataFrame timestamps and track values\n",
    "    window_timestamps = df_orig['Timestamp'].values\n",
    "    print(\"Plotting range:\", window_timestamps.min(), window_timestamps.max())\n",
    "    print(\"First spike timestamp in df_val_range:\", first_ts_df_val_range)\n",
    "    filtered_df_val_range = df_val_range[(df_val_range['ts'] >= window_timestamps.min()) & \n",
    "                                     (df_val_range['ts'] <= window_timestamps.max())]\n",
    "\n",
    "    # Iterate over the filtered DataFrame\n",
    "    y_top = df_orig['Samples'].max() * 1.1  # Slightly above the max sample value\n",
    "    y_bottom = df_orig['Samples'].min() * 1.1\n",
    "    for index, row in filtered_df_val_range.iterrows():\n",
    "        color = track_colors.get(int(row['track']), 'black')  # Default to black if track color is not found\n",
    "        \n",
    "        # Plot a circle at the top position\n",
    "        plt.scatter(row['ts'], y_top, color=color, s=100, alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "\n",
    "        # Plot a circle at the bottom position\n",
    "        plt.scatter(row['ts'], y_bottom, color=color, s=100, alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "    #for index, row in filtered_df_val_range.iterrows():\n",
    "    #    plt.axvline(x=row['ts'], color=track_colors[int(row['track'])], linestyle='--', lw=2)\n",
    "\n",
    "    # Add legends\n",
    "    plt.legend(handles=legend_elements + track_legend_elements, title=\"Probability (%) and Track\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.xlabel('Sample index')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.gca().xaxis.set_major_locator(mticker.MaxNLocator(nbins=30))  # Increase the number of x-ticks\n",
    "    plt.gca().xaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f'{x:.8f}'))\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show(block=True)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming `original_val_samples` and `original_val_ts` are already defined\n",
    "# Select the first 45 values\n",
    "df = dataSet.all_differentiated_spikes\n",
    "num_values_to_plot = 100\n",
    "\n",
    "# Ensure the original sequences have enough data\n",
    "if len(original_val_samples) < num_values_to_plot or len(original_val_ts) < num_values_to_plot:\n",
    "    raise ValueError(\"Not enough data to plot the specified number of values.\")\n",
    "\n",
    "# Get the data to plot\n",
    "samples_to_plot = original_val_samples[:num_values_to_plot]\n",
    "timestamps_to_plot = original_val_ts[:num_values_to_plot]\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.close()\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.scatter(timestamps_to_plot, samples_to_plot, color='blue', alpha=0.6)\n",
    "plt.title('Scatter Plot of Original Value Samples')\n",
    "plt.xlabel('Timestamps')\n",
    "plt.ylabel('Samples')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "microneurography",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
