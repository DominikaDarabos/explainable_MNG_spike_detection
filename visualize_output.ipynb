{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "sys.path.append(module_path)\n",
    "\n",
    "from MicroneurographyDataloader import *\n",
    "from _external.WHVPNet_pytorch.networks import *\n",
    "from _external.WHVPNet_tensorflow.VPLayer import *\n",
    "from spike_classification import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.collections import LineCollection\n",
    "import matplotlib.ticker as mticker\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load the model.\n",
    "\"\"\"\n",
    "\n",
    "model_name = '_trained_models/widnow_15_overlapping_11_hidden_6_nweight_4_id_6'\n",
    "\n",
    "dtype = torch.float64\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "window_size = 15\n",
    "overlapping_size = 11\n",
    "\n",
    "MNG_dataloader = MicroneurographyDataloader()\n",
    "path = f'window_{window_size}_overlap_{overlapping_size}_corrected.pkl'\n",
    "MNG_dataloader.load_samples_and_labels_from_file(path)\n",
    "\n",
    "dataloaders = MNG_dataloader.sequential_split_with_resampling(1024)\n",
    "\n",
    "sample_windows = torch.tensor(MNG_dataloader.raw_data_windows, dtype=torch.float64).unsqueeze(1)\n",
    "n_channels, n_in = sample_windows[0].shape\n",
    "n_out = len(MNG_dataloader.binary_labels_onehot[0])\n",
    "num_VP_features = 6\n",
    "num_weights = 4\n",
    "fcn_neurons = 6\n",
    "affin = torch.tensor([6 / n_in, -0.3606]).tolist()\n",
    "weight = ((torch.rand(num_weights)-0.5)*8).tolist()\n",
    "\n",
    "\n",
    "model = VPNet(n_in, n_channels, num_VP_features, VPTypes.FEATURES, affin + weight, WeightedHermiteSystem(n_in, num_VP_features, num_weights), [fcn_neurons], n_out, device=device, dtype=dtype)\n",
    "model.load_state_dict(torch.load(model_name, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Window-wise multi-class comparison\n",
      "========================================\n",
      "{\n",
      "    \"Label 0\": {\n",
      "        \"TN\": 387548,\n",
      "        \"FP\": 15258\n",
      "    },\n",
      "    \"Label 1\": {\n",
      "        \"TP\": 259,\n",
      "        \"FN\": 0\n",
      "    },\n",
      "    \"Label 2\": {\n",
      "        \"TP\": 255,\n",
      "        \"FN\": 0\n",
      "    },\n",
      "    \"Label 3\": {\n",
      "        \"TP\": 236,\n",
      "        \"FN\": 17\n",
      "    }\n",
      "}\n",
      "========================================\n",
      "========================================\n",
      "Accuracy: 96.22%, loss: 10.2869\n",
      "Weighted Balanced Accuracy: 0.9700\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Evaluation.\n",
    "\"\"\"\n",
    "dataset_name='val' # 'or test\n",
    "decision_boundary = 0.8\n",
    "class_weights = torch.tensor([0.003, 0.997]).to(device)\n",
    "weighted_criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "criterion = VPLoss(weighted_criterion, 0.1)\n",
    "accuracy, loss, binary_labels, multiple_labels, predicted_classes, predicted_probabilities = test(model, dataloaders[f'{dataset_name}_loader'], criterion, decision_boundary)\n",
    "# compute_common_metrics(binary_labels, predicted_classes)\n",
    "# compute_merged_metrics(binary_labels, predicted_classes)\n",
    "# create_decision_ceratinty_boxplots(binary_labels, multiple_labels, predicted_classes, predicted_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get samples and timestamps from the dataloader.\n",
    "\"\"\"\n",
    "\n",
    "sample_windows = []\n",
    "for data in dataloaders[f'{dataset_name}_loader']:\n",
    "    x, labels, multiple = data\n",
    "    sample_windows.append(x.cpu())\n",
    "sample_windows = torch.cat(sample_windows).squeeze(1)\n",
    "timestamp_windows = dataloaders[f'{dataset_name}_timestamps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Retrieve information for the output plot.\n",
    "\"\"\"\n",
    "\n",
    "def reconstruct_original_sequence(overlapping_windows, window_size, overlapping):\n",
    "    \"\"\"\n",
    "    Transforms back the overlapping windows into a one dimensional sequence.\n",
    "    \"\"\"\n",
    "    overlapping_windows = np.asarray(overlapping_windows)\n",
    "    num_windows = len(overlapping_windows)\n",
    "    stride = window_size - overlapping\n",
    "    original_length = (num_windows - 1) * stride + window_size\n",
    "\n",
    "    reconstructed_sequence = np.zeros(original_length)\n",
    "    for i in range(num_windows):\n",
    "        start_index = i * stride\n",
    "        end_index = start_index + window_size\n",
    "        reconstructed_sequence[start_index:end_index] = overlapping_windows[i]\n",
    "    reconstructed_sequence = np.nan_to_num(reconstructed_sequence)\n",
    "    return reconstructed_sequence\n",
    "\n",
    "\n",
    "original_samples_seq = reconstruct_original_sequence(sample_windows, window_size, overlapping_size)\n",
    "original_timestamps_seq = reconstruct_original_sequence(timestamp_windows, window_size, overlapping_size)\n",
    "\n",
    "start_ts = original_timestamps_seq[0]\n",
    "end_ts = original_timestamps_seq[-1]\n",
    "start_index = MNG_dataloader.all_spikes_df['ts'].searchsorted(start_ts, side='left')\n",
    "end_index = MNG_dataloader.all_spikes_df['ts'].searchsorted(end_ts, side='right')\n",
    "ground_truth_spikes_in_dataset = MNG_dataloader.all_spikes_df.iloc[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predicted_classes.cpu().numpy()\n",
    "valid_intervals = generate_filtered_intervals(y_pred, multiple_labels, proximity_rule=True, latency_threshold=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of remained positives: 3007 num of deleted positives: 13001\n"
     ]
    }
   ],
   "source": [
    "def transform_predictions_to_sequence(predicted_probabilities, overlapping_windows, window_size, overlapping, decision_boundary, valid_intervals=None):\n",
    "    \"\"\"\n",
    "    Transforms overlapping windows with prediction probabilities back into a one-dimensional sequence.\n",
    "    Each datapoint receives averaged probabilities from the different windows it was present in.\n",
    "    \n",
    "    If a window is a positive prediction but not in a valid interval, its probability is set below the decision boundary.\n",
    "    \"\"\"\n",
    "    \n",
    "    predicted_probs_np = np.asarray(predicted_probabilities[:, 1])\n",
    "    overlapping_windows = np.asarray(overlapping_windows)\n",
    "    num_windows = len(overlapping_windows)\n",
    "    stride = window_size - overlapping\n",
    "    original_length = (num_windows - 1) * stride + window_size\n",
    "\n",
    "    transformed_sequence = np.zeros(original_length)\n",
    "    count_array = np.zeros(original_length)\n",
    "    counter_TP = 0\n",
    "    counter_deleted = 0\n",
    "    for i in range(num_windows):\n",
    "        start_index = i * stride\n",
    "        end_index = start_index + window_size\n",
    "\n",
    "        if valid_intervals is not None:\n",
    "            is_positive_prediction = predicted_probs_np[i] >= decision_boundary\n",
    "            #is_in_valid_interval = any(start <= start_index < start + length for start, length in valid_intervals)\n",
    "            is_in_valid_interval = False\n",
    "            if is_positive_prediction and i >= valid_intervals[0][0]:\n",
    "                for idx, (start, length) in enumerate(valid_intervals):\n",
    "                    if start <= i < start + length:\n",
    "                        is_in_valid_interval = True\n",
    "                        break\n",
    "\n",
    "            if is_positive_prediction and not is_in_valid_interval:\n",
    "                modified_prob = decision_boundary - 0.01 # decision_boundary - 0.01\n",
    "                counter_deleted += 1\n",
    "            else:\n",
    "                if is_positive_prediction and is_in_valid_interval:\n",
    "                    counter_TP += 1\n",
    "                modified_prob = predicted_probs_np[i]\n",
    "\n",
    "            # maximum probs \n",
    "            # transformed_sequence[start_index:end_index] = np.maximum(transformed_sequence[start_index:end_index], modified_prob)\n",
    "\n",
    "            #avg probs\n",
    "            transformed_sequence[start_index:end_index] += modified_prob\n",
    "            count_array[start_index:end_index] += 1\n",
    "        else:\n",
    "            transformed_sequence[start_index:end_index] += predicted_probs_np[i]\n",
    "            count_array[start_index:end_index] += 1\n",
    "\n",
    "    non_zero_count_mask = count_array > 0\n",
    "    transformed_sequence[non_zero_count_mask] /= count_array[non_zero_count_mask]\n",
    "    transformed_sequence = np.nan_to_num(transformed_sequence)\n",
    "    if valid_intervals is not None:\n",
    "        print(\"num of remained positives:\", counter_TP, \"num of deleted positives:\", counter_deleted)\n",
    "\n",
    "    return transformed_sequence\n",
    "\n",
    "prediction_sequence = transform_predictions_to_sequence(predicted_probabilities, timestamp_windows, window_size, overlapping_size, decision_boundary=decision_boundary, valid_intervals=valid_intervals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_output_windows():\n",
    "    \"\"\"\n",
    "    sample_size : how many datapoints should be included in one plot.\n",
    "    plotting_start_idx = from where the plotting should start.\n",
    "    num_of_plots = the number of plots the code should generate after each other.\n",
    "    \"\"\"\n",
    "    # sample_size = 3000\n",
    "    # plotting_start_idx = 181200\n",
    "    # sample_size = 500\n",
    "    # plotting_start_idx = 63600\n",
    "    sample_size = 1000\n",
    "    plotting_start_idx = 63350\n",
    "    num_of_plots = 1\n",
    "\n",
    "    # probability bins for the coloring and legend\n",
    "    prob_bin_colors = ['#C0C0C0', 'khaki', '#FFA500', '#FF0000']\n",
    "    bin_limits = [0, 50, 80, 98, 100]\n",
    "    percentage_labels = ['0-50%', '50-80%', '80-98%', '98-100%']\n",
    "    legend_elements = [Line2D([0], [0], marker='o', color='w', label=label, markerfacecolor=prob_bin_colors[i], markersize=10)\n",
    "                       for i, label in enumerate(percentage_labels)]\n",
    "\n",
    "    # spikes for legend\n",
    "    unique_tracks = MNG_dataloader.track_replacement_dict.values()\n",
    "    marker_styles = ['s', '^', 'D', 'p', '*', 'h', 'H', '+', 'x', '|', '_', 'v', '<', '>', '8', 'P', 'X']\n",
    "    track_markers = {track: marker_styles[i % len(marker_styles)] for i, track in enumerate(unique_tracks)}\n",
    "    spike_labels = [f'Spike {track-1}' if track != 1 else 'Stimulus' for track in unique_tracks]\n",
    "\n",
    "    track_legend_elements = [\n",
    "        Line2D([0], [0], color='black', marker=track_markers[track_num], linestyle='None', markersize=10, label=label)\n",
    "        for track_num, label in zip(unique_tracks, spike_labels)\n",
    "    ]\n",
    "\n",
    "    y_min_all = sample_windows.min() * 1.2\n",
    "    y_max_all = sample_windows.max() * 1.2\n",
    "    for start_index in range(plotting_start_idx, plotting_start_idx+sample_size*num_of_plots, sample_size):\n",
    "        end_index = start_index + sample_size\n",
    "        timesamps_to_plot_np = np.asarray(original_timestamps_seq[start_index:end_index])\n",
    "        samples_to_plot_np = original_samples_seq[start_index:end_index]\n",
    "        probs_to_plot_np = prediction_sequence[start_index:end_index]\n",
    "\n",
    "        plt.figure(figsize=(20, 6))\n",
    "\n",
    "        # Define color bins based on val_probabilities_class1\n",
    "        probability_map = np.digitize(probs_to_plot_np * 100, bins=bin_limits) - 1\n",
    "        probability_map = np.clip(probability_map, 0, len(prob_bin_colors) - 1)\n",
    "\n",
    "        ts_sample_points = np.array([timesamps_to_plot_np, samples_to_plot_np]).T.reshape(-1, 1, 2)\n",
    "        segments = np.concatenate([ts_sample_points[:-1], ts_sample_points[1:]], axis=1)\n",
    "        line_colors = [prob_bin_colors[probability_map[i]] for i in range(len(probability_map) - 1)]\n",
    "        lc = LineCollection(segments, colors=line_colors, linewidths=3, alpha=0.8)\n",
    "        ax = plt.gca()\n",
    "        ax.add_collection(lc)\n",
    "\n",
    "        ground_truth_spikes_to_plot = ground_truth_spikes_in_dataset[(ground_truth_spikes_in_dataset['ts'] >= timesamps_to_plot_np.min()) & \n",
    "                                              (ground_truth_spikes_in_dataset['ts'] <= timesamps_to_plot_np.max())]\n",
    "\n",
    "        if ground_truth_spikes_to_plot.empty:\n",
    "            print(f\"No ground truth spikes present between timestamps {timesamps_to_plot_np.min()} - {timesamps_to_plot_np.max()}\")\n",
    "            plt.plot()\n",
    "\n",
    "        y_top = y_max_all * 0.9\n",
    "        y_bottom = y_min_all * 0.9\n",
    "\n",
    "        track_marker_map = {track: marker_styles[i % len(marker_styles)] for i, track in enumerate(unique_tracks)}\n",
    "        for index, spike_row in ground_truth_spikes_to_plot.iterrows():\n",
    "            color = 'black'\n",
    "            marker = track_marker_map.get(int(spike_row['track']), 'o')\n",
    "\n",
    "            # vertical marks for the spikes\n",
    "            plt.scatter(spike_row['ts'], y_top, color=color, marker=marker, s=150)\n",
    "            plt.scatter(spike_row['ts'], y_bottom, color=color, marker=marker, s=150, label=spike_row['track'])\n",
    "            plt.axvline(x=spike_row['ts'], color=color, linestyle='--', lw=0.5)\n",
    "        \n",
    "\n",
    "        plt.ylim(y_min_all, y_max_all)\n",
    "        plt.xlim(timesamps_to_plot_np.min(), timesamps_to_plot_np.max())\n",
    "        plt.legend(handles=legend_elements + track_legend_elements, title=\"Probability and Spike\", bbox_to_anchor=(1, 1.04), loc='upper left', fontsize=18, title_fontsize=18)\n",
    "        plt.xlabel('Timestamp', fontsize=18)\n",
    "        plt.ylabel('Amplitude', fontsize=18)\n",
    "        plt.grid(axis='y', linestyle=':', linewidth=1)\n",
    "        plt.gca().xaxis.set_major_locator(mticker.MaxNLocator(nbins=30))\n",
    "        plt.gca().xaxis.set_major_formatter(mticker.FuncFormatter(lambda x, _: f'{x:.4f}'))\n",
    "        plt.xticks(rotation=45, ha='right', fontsize=16)\n",
    "        plt.yticks(fontsize=18)\n",
    "        plt.tight_layout()\n",
    "        plt.grid(False)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "plot_output_windows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "microneurography",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
